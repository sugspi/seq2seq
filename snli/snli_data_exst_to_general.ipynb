{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import xml.etree.ElementTree as ET\n",
    "import ast\n",
    "\n",
    "from __future__ import print_function\n",
    "from gensim import corpora\n",
    "\n",
    "from nltk.sem.logic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ここを外部読み込みにさせたい.\n",
    "predicate_arr = []\n",
    "pre_pre = []\n",
    "variable_arr = []\n",
    "pre_var = []\n",
    "formulas = []\n",
    "check_dup = set([])\n",
    "\n",
    "from nltk.sem.logic import LogicParser\n",
    "from nltk.sem.logic import *\n",
    "\n",
    "logic_parser = LogicParser(type_check=False)\n",
    "def lexpr(formula_str):\n",
    "    return logic_parser.parse(formula_str)\n",
    "\n",
    "def normalize_interpretation(expression):\n",
    "    norm_interp_str = coq_string_expr(expression)\n",
    "    return norm_interp_str\n",
    "def coq_string_expr(expression):    \n",
    "    if isinstance(expression, str):\n",
    "        expression = lexpr(expression)\n",
    "    expr_coq_str = ''\n",
    "    if isinstance(expression, ApplicationExpression):\n",
    "        expr_coq_str = coq_string_application_expr(expression)\n",
    "    elif isinstance(expression, AbstractVariableExpression):\n",
    "        expr_coq_str = coq_string_abstract_variable_expr(expression)\n",
    "    elif isinstance(expression, LambdaExpression):\n",
    "        expr_coq_str = coq_string_lambda_expr(expression)\n",
    "    elif isinstance(expression, QuantifiedExpression):\n",
    "        pre_var.append('(')\n",
    "        pre_var.append(')')\n",
    "        quantifier = {'exists' : 'exists','exist' : 'exists','all' : 'forall','forall' : 'forall'}\n",
    "        quant = expression.getQuantifier()\n",
    "        if quant in quantifier:\n",
    "            quant = nltk2coq_quantifier[expression.getQuantifier()]\n",
    "        if(quant == 'exists'):\n",
    "            pre_var.append('exist')\n",
    "        elif(quant == 'forall'):\n",
    "            pre_var.append('forall')\n",
    "        expr_coq_str = coq_string_quantified_expr(expression)\n",
    "    elif isinstance(expression, AndExpression):\n",
    "        pre_var.append('(')\n",
    "        pre_var.append(')')\n",
    "        pre_var.append('and')\n",
    "        expr_coq_str = coq_string_and_expr(expression)\n",
    "    elif isinstance(expression, OrExpression):\n",
    "        pre_var.append('(')\n",
    "        pre_var.append(')')\n",
    "        pre_var.append('or')\n",
    "        expr_coq_str = coq_string_or_expr(expression)\n",
    "    elif isinstance(expression, NegatedExpression):\n",
    "        pre_var.append('(')\n",
    "        pre_var.append(')')\n",
    "        pre_var.append('not')\n",
    "        expr_coq_str = coq_string_not_expr(expression)\n",
    "    elif isinstance(expression, BinaryExpression):\n",
    "        pre_var.append('(')\n",
    "        pre_var.append(')')\n",
    "        pre_var.append('=')\n",
    "        expr_coq_str = coq_string_binary_expr(expression)\n",
    "    elif isinstance(expression, Variable):\n",
    "        expr_coq_str = '%s' % expression\n",
    "    else:\n",
    "        expr_coq_str = str(expression)\n",
    "    return expr_coq_str\n",
    "\n",
    "coqstr = coq_string_expr\n",
    "\n",
    "def coq_string_application_expr(expression):\n",
    "    # uncurry the arguments and find the base function\n",
    "    if expression.is_atom():\n",
    "        #is_atom : 原子論理式かどうか\n",
    "        function, args = expression.uncurry()\n",
    "        arg_str = ' '.join(\"%s\" % coqstr(arg) for arg in args)\n",
    "    else:\n",
    "        #Leave arguments curried\n",
    "        function = expression.function\n",
    "        arg_str = \"%s\" % coqstr(expression.argument)\n",
    "\n",
    "    function_str = \"%s\" % coqstr(function)\n",
    "    parenthesize_function = False\n",
    "    if isinstance(function, LambdaExpression):\n",
    "        if isinstance(function.term, ApplicationExpression):\n",
    "            if not isinstance(function.term.function,\n",
    "                              AbstractVariableExpression):\n",
    "                parenthesize_function = True\n",
    "        elif not isinstance(function.term, BooleanExpression):\n",
    "            parenthesize_function = True\n",
    "    elif isinstance(function, ApplicationExpression):\n",
    "        parenthesize_function = True\n",
    "\n",
    "    if parenthesize_function:\n",
    "        function_str = Tokens.OPEN + function_str + Tokens.CLOSE\n",
    "    \n",
    "    return Tokens.OPEN + function_str + ' ' + arg_str + Tokens.CLOSE\n",
    "\n",
    "reserved_s = \\\n",
    "  {'AND' : 'and', 'OR' : 'or', 'neg' : 'not', 'EMPTY' : '', 'TrueP' : 'True'}\n",
    "def coq_string_abstract_variable_expr(expression):\n",
    "    expr_str = str(expression.variable)\n",
    "    if expr_str in reserved_s:\n",
    "        expr_str = reserved_s[expr_str] #Trueしか置換できていない可能性あり\n",
    "    if not isinstance(expression, FunctionVariableExpression):\n",
    "        if expr_str == '':\n",
    "            expr_str = \"%s\" % expr_str\n",
    "        else:\n",
    "            expr_str = \"%s\" % expr_str\n",
    "    else:\n",
    "        expr_str = \"%s\" % expr_str\n",
    "        \n",
    "    if not re.sub(r'_', \"\",expr_str) in check_dup:\n",
    "        if expr_str.startswith('_'):\n",
    "            #expr_str = re.sub(r'_', \"\", expr_str)\n",
    "            pre_pre.append(expr_str)\n",
    "            check_dup.add(expr_str)\n",
    "            #print(\"pre\",expr_str)\n",
    "        else :\n",
    "            pre_var.append(expr_str)\n",
    "            check_dup.add(expr_str)\n",
    "            #print(\"var\",expr_str)\n",
    "    return expr_str\n",
    "\n",
    "def coq_string_lambda_expr(expression):\n",
    "    variables = [expression.variable]\n",
    "    term = expression.term\n",
    "    while term.__class__ == expression.__class__:\n",
    "        variables.append(term.variable)\n",
    "        term = term.term\n",
    "    return Tokens.OPEN + 'fun ' + ' '.join(\"%s\" % coqstr(v) for v in variables) + \\\n",
    "           ' => ' + \"%s\" % coqstr(term) + Tokens.CLOSE\n",
    "\n",
    "nltk2coq_quantifier = {'exists' : 'exists','exist' : 'exists','all' : 'forall','forall' : 'forall'}\n",
    "def coq_string_quantified_expr(expression):\n",
    "    variables = [expression.variable]\n",
    "    term = expression.term\n",
    "    while term.__class__ == expression.__class__:\n",
    "        variables.append(term.variable)\n",
    "        term = term.term\n",
    "    nltk_quantifier = expression.getQuantifier()\n",
    "    # Rename quantifiers, according to coq notation. Such renaming dictionary\n",
    "    # is defined above as \"nltk2coq_quantifier\". If a rename convention is not\n",
    "    # available, use the same as in NLTK.\n",
    "    if nltk_quantifier in nltk2coq_quantifier:\n",
    "        coq_quantifier = nltk2coq_quantifier[expression.getQuantifier()]\n",
    "    else:\n",
    "        coq_quantifier = nltk_quantifier\n",
    "    return Tokens.OPEN + coq_quantifier + ' ' \\\n",
    "           + ' '.join(\"%s\" % coqstr(v) for v in variables) + \\\n",
    "           '. ' + \"%s\" % coqstr(term) + Tokens.CLOSE\n",
    "\n",
    "def coq_string_and_expr(expression):\n",
    "    first = coqstr(expression.first)\n",
    "    second = coqstr(expression.second)\n",
    "    return Tokens.OPEN + 'and ' + first + ' ' + second + Tokens.CLOSE\n",
    "\n",
    "\n",
    "def coq_string_or_expr(expression):\n",
    "    first = coqstr(expression.first)\n",
    "    second = coqstr(expression.second)\n",
    "    return Tokens.OPEN + 'or ' + first + ' ' + second + Tokens.CLOSE\n",
    "\n",
    "def coq_string_not_expr(expression):\n",
    "    term_str = coqstr(expression.term)\n",
    "    return Tokens.OPEN + 'not ' + term_str + Tokens.CLOSE\n",
    "\n",
    "def coq_string_binary_expr(expression):\n",
    "    first = coqstr(expression.first)\n",
    "    second = coqstr(expression.second)\n",
    "    return Tokens.OPEN + first + ' ' + expression.getOp() \\\n",
    "            + ' ' + second + Tokens.CLOSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituteString(text,lst):\n",
    "    ###辞書作り###\n",
    "    lst = list(set(lst))\n",
    "    e_sub = {}\n",
    "    z_sub = {}\n",
    "    ice = 0 #index counter\n",
    "    icz = 0 \n",
    "\n",
    "    for i in lst:\n",
    "        matchObj = re.search(r'e0+', i)\n",
    "        if(matchObj):\n",
    "            tmp = \"e0\"+str(ice)\n",
    "            e_sub[tmp] = i\n",
    "            ice+=1\n",
    "            continue\n",
    "        matchObj = re.search(r'z[0-9]*', i)\n",
    "        if matchObj:\n",
    "            tmp = \"z0\"+str(icz)\n",
    "            z_sub[tmp] = i\n",
    "            icz+=1\n",
    "    \n",
    "    e_sub = {v:k for k, v in e_sub.items()}\n",
    "    z_sub = {v:k for k, v in z_sub.items()}\n",
    "    #############\n",
    "    \n",
    "    for k, v in e_sub.items():  \n",
    "        text = text.replace(k,v)\n",
    "    for k, v in z_sub.items():  \n",
    "        text = text.replace(k,v)\n",
    "    #print (text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19949\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n",
      "faild parse\n"
     ]
    }
   ],
   "source": [
    "#en_parsed のsemから取り出し ただし，論理記号の順番がスタック式をなおさなければならなそう\n",
    "tree = ET.parse('sem/snli_dev.txt.candc.sem.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "root = root[0]\n",
    "root = root[0] #１個目のsentence\n",
    "\n",
    "mydict = {}\n",
    "c = 0 #辞書のindexを回す\n",
    "print(len(root))\n",
    "\n",
    "#子階層のタグと中身\n",
    "for child in root:\n",
    "    \n",
    "    formula = child[2]  #child[2]がsemantics\n",
    "    check = (child[2].attrib)\n",
    "    check = check['status']\n",
    "   \n",
    "    if(check == 'success'):\n",
    "        plain = \"\"\n",
    "        toridashi = child[0]\n",
    "        \n",
    "        for i in toridashi :\n",
    "            p = i.attrib\n",
    "            p = p['surf']\n",
    "            if(p=='.' or p== ','):\n",
    "                plain = plain + p\n",
    "            else :\n",
    "                plain = plain + \" \" + p\n",
    "        plain = plain+'\\n'\n",
    "        \n",
    "        #print(plain)\n",
    "        \n",
    "        formula = child[2][0]\n",
    "        formula = (formula.attrib)\n",
    "        formula = formula['sem'] #\\nが付与されていると信じている\n",
    "        \n",
    "        #論理式を今回の標準にする\n",
    "        check_dup = set([])\n",
    "        pre_pre = []\n",
    "        pre_var = []\n",
    "        \n",
    "        try:\n",
    "            formula = coq_string_expr(formula)\n",
    "            formula = substituteString(formula,pre_var)\n",
    "            predicate_arr.append(pre_pre)\n",
    "            \n",
    "            ice = 0\n",
    "            icz = 0\n",
    "            \n",
    "            for i in range(len(pre_var)):\n",
    "                matchObj = re.search(r'e0+', pre_var[i])\n",
    "                if(matchObj):\n",
    "                    tmp = \"e0\"+str(ice)\n",
    "                    #print(\"p: \",pre_var[i])\n",
    "                    pre_var[i] = tmp\n",
    "                    #print(\"t:\" ,tmp )\n",
    "                    #print(\"np: \",pre_var[i])\n",
    "                    continue\n",
    "                matchObj = re.search(r'z[0-9]*', pre_var[i])\n",
    "                if matchObj:\n",
    "                    #print(\"p: \",pre_var[i])\n",
    "                    tmp = \"z0\"+str(icz)\n",
    "                    pre_var[i] = tmp\n",
    "                    #print(\"t: \",tmp)\n",
    "                    #print(\"np: \",pre_var[i])\n",
    "                    icz+=1\n",
    "                    \n",
    "            #print(pre_var)\n",
    "            variable_arr.append(pre_var)\n",
    "            test_val = pre_var #置換用のテスト\n",
    "            test_fomula = formula\n",
    "            pre_pre = []\n",
    "            pre_var = []\n",
    "            pair = {'text':plain,'formula':formula}\n",
    "            mydict.update({str(c):pair})\n",
    "        except:\n",
    "            #import traceback\n",
    "            #traceback.print_exc()\n",
    "            #raise\n",
    "            #print(i,\" : \",formula)\n",
    "            #print('\\n')\n",
    "            pre_pre = []\n",
    "            pre_var = []\n",
    "    else:\n",
    "      print('faild parse')\n",
    "    #c+=1\n",
    "    #if(c==100):\n",
    "    #    break\n",
    "    \n",
    "#f = open('snli_input_data_100_1208.json', 'w') # 書き込みモードで開く\n",
    "#json.dump(mydict, f,ensure_ascii=False)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (* x, (& (& (& (& (& (woman x) (two x)) True) (* e, (& (& (embrace e) ((Subj e) = x)) True))) (* e, (& (& (hold e) ((Subj e) = x)) True))) (* z00, (& (& (package z00) True) (* e, (& (& (& (go e) ((Subj e) = x)) ((Acc e) = z00)) True))))))\n",
      "after:  * x, & & & & & woman x two x True * e, & & embrace e Subj e = x True * e, & & hold e Subj e = x True * z00, & & package z00 True * e, & & & go e Subj e = x Acc e = z00 True\n"
     ]
    }
   ],
   "source": [
    "f =  open('snli_input_data_1206_100.json')\n",
    "json_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "org = \"exists x.(_woman(x) & _two(x) & TrueP & exists e.(_embrace(e) & (Subj(e) = x) & TrueP) & exists e.(_hold(e) & (Subj(e) = x) & TrueP) & exists z1.(_package(z1) & TrueP & exists e.(_go(e) & (Subj(e) = x) & (Acc(e) = z1) & TrueP))\"\n",
    "\n",
    "\n",
    "for i in json_data :\n",
    "    lis = json_data[i]\n",
    "    txt = (lis['text'])\n",
    "    fom = (lis['formula'])\n",
    "    print(\"before: \",fom)\n",
    "    fom = re.sub(r'\\(', \"\", fom)\n",
    "    fom = re.sub(r'\\)', \"\", fom)\n",
    "    print(\"after: \",fom)\n",
    "    break\n",
    "    \n",
    "/*org before after みると確実にバグある*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dict = corpora.Dictionary(predicate_arr)\n",
    "#pre_dict.filter_extremes(no_below=4, no_above=0.4)\n",
    "pre_dict.save_as_text('itemdic_predicates_nofilter_1208.txt')\n",
    "\n",
    "val_dict = corpora.Dictionary(variable_arr)\n",
    "#val_dict.filter_extremes(no_below=4, no_above=0.4)\n",
    "val_dict.save_as_text('itemdic_variables_nofilter_1208.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'Subj', 'x', 'z65', 'True', 'e068', 'z73', 'z69', 'Acc', 'z71', 'z66', 'z67']\n"
     ]
    }
   ],
   "source": [
    "print(variables[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
